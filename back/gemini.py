import google.generativeai as genai
from config import settings
import json
import re
from datetime import datetime, timedelta
import requests
import base64
from io import BytesIO
import uuid
import os
from google.cloud import texttospeech
import vertexai
try:
    from google import genai as google_genai
    from google.genai import types
except ImportError:
    # Fallback to old API if new one is not available
    from vertexai.preview.vision_models import ImageGenerationModel

# é…ç½®Gemini API
if settings.GEMINI_BASE_URL != "https://generativelanguage.googleapis.com":
    # ä½¿ç”¨ä»£ç†æ—¶ï¼Œé€šè¿‡requestsç›´æ¥è°ƒç”¨
    print(f"Using Gemini proxy: {settings.GEMINI_BASE_URL}")
else:
    # ç›´æ¥ä½¿ç”¨Google SDK
    genai.configure(api_key=settings.GEMINI_API_KEY)
    print("Using direct Gemini API access")

# Set Google Cloud credentials
credentials_path = os.path.join(os.path.dirname(__file__), "service-account-key.json", "gen-lang-client-0374473221-e19a8e500cef.json")
if os.path.exists(credentials_path):
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
    print(f"Google Cloud credentials set: {credentials_path}")
else:
    print(f"Warning: Google Cloud credentials file not found: {credentials_path}")

# Initialize Vertex AI with explicit credentials
try:
    from google.oauth2 import service_account
    if os.path.exists(credentials_path):
        credentials = service_account.Credentials.from_service_account_file(credentials_path)
        vertexai.init(project=settings.GOOGLE_CLOUD_PROJECT_ID, location=settings.GOOGLE_CLOUD_LOCATION, credentials=credentials)
        print(f"Vertex AI initialized with explicit credentials for project: {settings.GOOGLE_CLOUD_PROJECT_ID}")
        
        # Initialize Google Gen AI SDK
        try:
            # Set environment variables for Vertex AI
            os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "true"
            os.environ["GOOGLE_CLOUD_PROJECT"] = settings.GOOGLE_CLOUD_PROJECT_ID
            os.environ["GOOGLE_CLOUD_LOCATION"] = settings.GOOGLE_CLOUD_LOCATION
            print("Google Gen AI SDK environment configured for Vertex AI")
        except Exception as genai_error:
            print(f"Google Gen AI SDK initialization failed: {genai_error}")
    else:
        vertexai.init(project=settings.GOOGLE_CLOUD_PROJECT_ID, location=settings.GOOGLE_CLOUD_LOCATION)
        print(f"Vertex AI initialized with default credentials for project: {settings.GOOGLE_CLOUD_PROJECT_ID}")
        
        # Initialize Google Gen AI SDK with default credentials
        try:
            # Set environment variables for Vertex AI
            os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "true"
            os.environ["GOOGLE_CLOUD_PROJECT"] = settings.GOOGLE_CLOUD_PROJECT_ID
            os.environ["GOOGLE_CLOUD_LOCATION"] = settings.GOOGLE_CLOUD_LOCATION
            print("Google Gen AI SDK environment configured for Vertex AI (default credentials)")
        except Exception as genai_error:
            print(f"Google Gen AI SDK initialization failed: {genai_error}")
except Exception as e:
    print(f"Warning: Vertex AI initialization failed: {e}")

SYSTEM_PROMPT_AIDS = """ä½ æ˜¯å°æä»è®°å¿†æ­å­ï¼Œè´Ÿè´£å¸®åŠ©ç”¨æˆ·è®°å¿†ã€‚ä½ ä¼šæ ¹æ®ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼Œç”Ÿæˆæ€ç»´å¯¼å›¾ã€è®°å¿†å£è¯€å’Œæ„Ÿå®˜è”æƒ³ã€‚

è®°å¿†å£è¯€ç”Ÿæˆä¸‰ç§ç±»å‹ï¼šé¡ºå£æºœè®°å¿†æ³•ã€é¦–å­—æ¯è®°å¿†æ³•ã€æ•…äº‹è”æƒ³æ³•ã€‚
æ„Ÿå®˜è”æƒ³ä¹Ÿåˆ†ä¸ºä¸‰ç±»ï¼šè§†è§‰è”æƒ³ã€å¬è§‰è”æƒ³å’Œè§¦è§‰è”æƒ³ã€‚

æ³¨æ„ä¸¥æ ¼æŒ‰ç…§å¦‚ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸éœ€è¦ä»»ä½•å¤šä½™çš„å†…å®¹ï¼Œåªéœ€è¦åœ¨å¯¹åº”çš„ä½ç½®å¡«å…¥ contentï¼š

{
  "mindMap": {
    "id": "root",
    "label": "content" æˆ– "è®°å¿†ä¸»é¢˜",
    "children": [
      {
        "id": "part1",
        "label": "content",
        "children": [
          { "id": "leaf1", "label": "content" },
          { "id": "leaf2", "label": "content" }
        ]
      },
      {
        "id": "part2",
        "label": "content",
        "children": [
          { "id": "leaf3", "label": "content" },
          { "id": "leaf4", "label": "content" }
        ]
      }
    ]
  },
  "mnemonics": [
    {
      "id": "rhyme",
      "title": "é¡ºå£æºœè®°å¿†æ³•",
      "content": "contentï¼Œé¡ºå£æºœåŠ©è®°ã€‚",
      "type": "rhyme"
    },
    {
      "id": "acronym",
      "title": "é¦–å­—æ³•",
      "content": "",
      "type": "acronym",
      "explanation": "åˆ©ç”¨é¦–å­—æ¯è®°å¿†"
    },
    {
      "id": "story",
      "title": "æ•…äº‹è”æƒ³æ³•",
      "content": "æƒ³è±¡ä¸€ä¸ªæ•…äº‹ä¸²è”ï¼š",
      "type": "story"
    }
  ],
  "sensoryAssociations": [
    {
      "id": "visual",
      "title": "è§†è§‰è”æƒ³",
      "type": "visual",
      "content": [
        {
          "dynasty": "content",
          "image": "ğŸŒŸ",
          "color": "#fbbf24",
          "association": ""
        },
        {
          "dynasty": "content",
          "image": "ğŸ”µ",
          "color": "#06b6d4",
          "association": ""
        }
      ]
    },
    {
      "id": "auditory",
      "title": "å¬è§‰è”æƒ³",
      "type": "auditory",
      "content": [
        { "dynasty": "content", "sound": "å®å’šå£°", "rhythm": "èŠ‚å¥æ„Ÿ" },
        { "dynasty": "content", "sound": "é£å£°", "rhythm": "è½»å¿«" }
      ]
    },
    {
      "id": "tactile",
      "title": "è§¦è§‰è”æƒ³",
      "type": "tactile",
      "content": [
        { "dynasty": "content", "texture": "æŸ”è½¯", "feeling": "æ¸©æš–" },
        { "dynasty": "content", "texture": "åšç¡¬", "feeling": "å†°å‡‰" }
      ]
    }
  ]
}
"""

# Although we ask Gemini for the schedule, it's more reliable to calculate it in code.
# The prompt serves as a logical guide, but the implementation is deterministic.
def generate_review_schedule_from_ebbinghaus():
    """
    Generates a review schedule based on the Ebbinghaus forgetting curve.
    """
    now = datetime.now()
    review_intervals = [
        timedelta(minutes=20),
        timedelta(hours=1),
        timedelta(hours=9),
        timedelta(days=1),
        timedelta(days=2),
        timedelta(days=4),
        timedelta(days=7),
        timedelta(days=15),
    ]
    review_dates = [(now + interval).isoformat() for interval in review_intervals]
    return {"review_dates": review_dates}

def parse_gemini_response(text: str):
    try:
        # Clean the text by removing ```json and ``` markers
        cleaned_text = re.sub(r'```json\n?|```', '', text)
        return json.loads(cleaned_text)
    except Exception as e:
        print(f"Error parsing Gemini response: {e}")
        return None

async def call_gemini_via_proxy(prompt: str, model_name: str = "gemini-1.5-flash"):
    """é€šè¿‡ä»£ç†è°ƒç”¨Gemini API"""
    try:
        url = f"{settings.GEMINI_BASE_URL}/v1beta/models/{model_name}:generateContent"
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": settings.GEMINI_API_KEY
        }
        
        payload = {
            "contents": [{
                "parts": [{
                    "text": prompt
                }]
            }]
        }
        
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        response.raise_for_status()
        
        result = response.json()
        if "candidates" in result and len(result["candidates"]) > 0:
            return result["candidates"][0]["content"]["parts"][0]["text"]
        else:
            print(f"Unexpected Gemini response format: {result}")
            return None
            
    except Exception as e:
        print(f"Error calling Gemini via proxy: {e}")
        return None

async def generate_memory_aids(content: str):
    prompt = f"{SYSTEM_PROMPT_AIDS}\n\nç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼š{content}\n\nè¯·ä¸ºè¿™ä¸ªå†…å®¹ç”Ÿæˆè®°å¿†è¾…åŠ©å·¥å…·."

    try:
        if settings.GEMINI_BASE_URL != "https://generativelanguage.googleapis.com":
            # ä½¿ç”¨ä»£ç†è°ƒç”¨
            response_text = await call_gemini_via_proxy(prompt)
        else:
            # ç›´æ¥ä½¿ç”¨SDKè°ƒç”¨
            model = genai.GenerativeModel('gemini-1.5-flash')
            response = await model.generate_content_async(prompt)
            response_text = response.text
        
        if response_text:
            # print("Gemini aids response:", response_text)
            parsed_response = parse_gemini_response(response_text)
            return parsed_response
        else:
            return None
    except Exception as e:
        print(f"Error calling Gemini API for aids: {e}")
        return None

async def generate_image(content: str, context: str = ""):
    """
    Generate an actual image based on the visual association content using Google Imagen
    """
    # First, generate a detailed prompt using Gemini
    prompt_generation = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒç”Ÿæˆæç¤ºè¯ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹è§†è§‰è”æƒ³å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„ã€é€‚åˆAIå›¾åƒç”Ÿæˆçš„è‹±æ–‡æç¤ºè¯ã€‚

è§†è§‰è”æƒ³å†…å®¹ï¼š{content}
ä¸Šä¸‹æ–‡ï¼š{context}

è¦æ±‚ï¼š
1. æç¤ºè¯åº”è¯¥æ˜¯è‹±æ–‡
2. æè¿°è¦å…·ä½“ã€ç”ŸåŠ¨
3. é€‚åˆè®°å¿†è¾…åŠ©çš„è§†è§‰åŒ–è¡¨è¾¾
4. é£æ ¼æ¸…æ™°ã€è‰²å½©é²œæ˜
5. åªè¿”å›æç¤ºè¯ï¼Œä¸è¦å…¶ä»–å†…å®¹

ç¤ºä¾‹æ ¼å¼ï¼š"A vibrant illustration of..."
"""

    try:
        # Generate the prompt
        if settings.GEMINI_BASE_URL != "https://generativelanguage.googleapis.com":
            # ä½¿ç”¨ä»£ç†è°ƒç”¨
            image_prompt = await call_gemini_via_proxy(prompt_generation)
        else:
            # ç›´æ¥ä½¿ç”¨SDKè°ƒç”¨
            model = genai.GenerativeModel('gemini-1.5-flash')
            prompt_response = await model.generate_content_async(prompt_generation)
            image_prompt = prompt_response.text
        
        if image_prompt:
            image_prompt = image_prompt.strip()
        else:
            return None
        
        try:
            # Try to generate the actual image using Google Gen AI SDK
            try:
                # Use new Google Gen AI SDK
                client = google_genai.Client(vertexai=True)
                response = client.models.generate_images(
                    model="imagen-3.0-generate-002",
                    prompt=image_prompt,
                    config=types.GenerateImagesConfig(
                        number_of_images=1,
                        include_rai_reason=True,
                        output_mime_type='image/jpeg'
                    )
                )
                
                # Get the generated image
                generated_image = response.generated_images[0]
                
                # The generated_image.image is a google.genai.types.Image object with image_bytes attribute
                if hasattr(generated_image, 'image') and hasattr(generated_image.image, 'image_bytes'):
                    image_bytes = generated_image.image.image_bytes
                    image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                elif hasattr(generated_image, 'image_bytes'):
                    image_bytes = generated_image.image_bytes
                    image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                else:
                    raise Exception(f"Unknown image object structure: {type(generated_image)}, attributes: {dir(generated_image)}")
                
            except (NameError, AttributeError, ImportError) as fallback_error:
                print(f"Falling back to legacy Vertex AI API: {fallback_error}")
                # Fallback to old API
                generation_model = ImageGenerationModel.from_pretrained("imagen-3.0-generate-001")
                response = generation_model.generate_images(
                    prompt=image_prompt,
                    number_of_images=1,
                    aspect_ratio="1:1",
                    add_watermark=False,
                )
                
                # Get the generated image
                generated_image = response.images[0]
                image_bytes = generated_image._image_bytes
                image_base64 = base64.b64encode(image_bytes).decode('utf-8')
            
            return {
                "image_url": None,  # Imagen doesn't provide URLs, only image data
                "image_base64": f"data:image/png;base64,{image_base64}",
                "prompt": image_prompt
            }
        except Exception as imagen_error:
            print(f"Imagen generation failed: {imagen_error}")
            # Return error information when image generation fails
            error_message = str(imagen_error)
            if "429" in error_message or "out of capacity" in error_message:
                raise Exception("å›¾ç‰‡ç”ŸæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚Google ImagenæœåŠ¡å½“å‰å®¹é‡ä¸è¶³ã€‚")
            elif "Unable to authenticate" in error_message:
                raise Exception("å›¾ç‰‡ç”ŸæˆæœåŠ¡è®¤è¯å¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥é…ç½®ã€‚")
            else:
                raise Exception(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š{error_message}")
            
            # This code won't be reached due to the raise above, but kept for reference
            return {
                "image_url": None,
                "image_base64": None,
                "prompt": image_prompt  # Still return the generated prompt
            }
            
    except Exception as e:
        print(f"Error generating image prompt: {e}")
        return {
            "image_url": None,
            "image_base64": None,
            "prompt": f"å›¾åƒç”Ÿæˆæç¤ºè¯ï¼š{content}çš„è§†è§‰åŒ–è¡¨è¾¾"  # Fallback prompt
        }

async def generate_audio(content: str, context: str = ""):
    """
    Generate actual audio based on the auditory association content.
    For environmental sounds (like truck engine), generate sound effects.
    For other content, use Text-to-Speech.
    """
    # Check if the content is requesting environmental sounds/effects
    environmental_sounds = [
        "å¼•æ“", "å‘åŠ¨æœº", "é©¬è¾¾", "æœºå™¨", "é£å£°", "é›¨å£°", "é›¨æ»´", "æµ·æµª", "é¸Ÿå«", "è™«é¸£", 
        "é›·å£°", "é’Ÿå£°", "è­¦æŠ¥", "æ±½ç¬›", "å–‡å­", "æ•²å‡»", "æ‘©æ“¦", "æ»´æ°´", "æµæ°´",
        "è„šæ­¥", "å¿ƒè·³", "å‘¼å¸", "å’€åš¼", "æ’•çº¸", "å¼€é—¨", "å…³é—¨", "é”®ç›˜", "é¼ æ ‡",
        "è½°é¸£", "å—¡å—¡", "å’”åš“", "æ»´ç­”", "å‘¼å‘¼", "å“—å“—", "å®å’š", "å˜€å—’"
    ]
    
    is_environmental_sound = any(sound in content for sound in environmental_sounds)
    
    if is_environmental_sound:
        # For environmental sounds, generate a synthetic sound effect description
        # and return a placeholder for actual sound generation
        model = genai.GenerativeModel('gemini-1.5-flash')
        sound_description = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å£°éŸ³æ•ˆæœæè¿°ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹å£°éŸ³å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„å£°éŸ³ç‰¹å¾æè¿°ã€‚

å£°éŸ³å†…å®¹ï¼š{content}
ä¸Šä¸‹æ–‡ï¼š{context}

è¦æ±‚ï¼š
1. æè¿°å£°éŸ³çš„é¢‘ç‡ç‰¹å¾ï¼ˆä½é¢‘ã€ä¸­é¢‘ã€é«˜é¢‘ï¼‰
2. æè¿°å£°éŸ³çš„èŠ‚å¥å’ŒæŒç»­æ€§
3. æè¿°å£°éŸ³çš„å¼ºåº¦å˜åŒ–
4. ç”¨ä¸“ä¸šæœ¯è¯­æè¿°å£°éŸ³ç‰¹å¾
5. é•¿åº¦æ§åˆ¶åœ¨100å­—ä»¥å†…

ç¤ºä¾‹æ ¼å¼ï¼š"ä½é¢‘æŒç»­è½°é¸£ï¼Œé¢‘ç‡çº¦50-200Hzï¼ŒèŠ‚å¥ç¨³å®šï¼Œå¼ºåº¦ä¸­ç­‰ï¼Œå¸¦æœ‰è½»å¾®çš„æœºæ¢°æŒ¯åŠ¨æ„Ÿ..."
"""
        
        try:
            response = await model.generate_content_async(sound_description)
            sound_spec = response.text.strip()
            
            # Return a structured response for environmental sounds
            return {
                "audio_base64": None,  # No actual audio generated yet
                "script": f"ç¯å¢ƒéŸ³æ•ˆï¼š{content}",
                "sound_description": sound_spec,
                "sound_type": "environmental",
                "duration": 5.0,  # Default 5 seconds for environmental sounds
                "message": "å·²ç”Ÿæˆå£°éŸ³ç‰¹å¾æè¿°ï¼Œå®é™…éŸ³æ•ˆç”ŸæˆåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
            }
        except Exception as e:
            print(f"Error generating sound description: {e}")
            return {
                "audio_base64": None,
                "script": f"ç¯å¢ƒéŸ³æ•ˆï¼š{content}",
                "sound_description": f"è¯·æ±‚çš„å£°éŸ³ï¼š{content}ï¼Œç‰¹å¾ï¼šæŒç»­æ€§ç¯å¢ƒéŸ³æ•ˆ",
                "sound_type": "environmental",
                "duration": 5.0,
                "message": "å£°éŸ³ç‰¹å¾æè¿°ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æè¿°"
            }
    
    # For non-environmental sounds, return development message instead of calling TTS API
    try:
        # Generate a simple script description without calling the model
        audio_script = f"å¬è§‰è”æƒ³ï¼š{content}"
        
        return {
            "audio_base64": None,
            "script": audio_script,
            "duration": 3.0,  # Default duration
            "message": "è¯­éŸ³åˆæˆåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
        }
        
    except Exception as e:
        print(f"Error generating audio script: {e}")
        return {
            "audio_base64": None,
            "script": f"å¬è§‰è”æƒ³ï¼š{content}",
            "duration": 3.0,
            "message": "è¯­éŸ³åˆæˆåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
        }

