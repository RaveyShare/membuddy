# å…¼å®¹æ€§å¯¼å…¥ - ä¿æŒå‘åå…¼å®¹
import google.generativeai as genai
from config import settings
import json
import re
from datetime import datetime, timedelta
import requests
import base64
from io import BytesIO
import uuid
import os
from google.cloud import texttospeech
import vertexai
import logging

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
try:
    from google import genai as google_genai
    from google.genai import types
except ImportError:
    # Fallback to old API if new one is not available
    from vertexai.preview.vision_models import ImageGenerationModel

# æ–°çš„AIç®¡ç†å™¨
from ai_manager import ai_manager, generate_memory_aids as ai_generate_memory_aids

# é…ç½®Gemini API
if settings.GEMINI_BASE_URL != "https://generativelanguage.googleapis.com":
    # ä½¿ç”¨ä»£ç†æ—¶ï¼Œé€šè¿‡requestsç›´æ¥è°ƒç”¨
    print(f"Using Gemini proxy: {settings.GEMINI_BASE_URL}")
else:
    # ç›´æ¥ä½¿ç”¨Google SDK
    genai.configure(api_key=settings.GEMINI_API_KEY)
    print("Using direct Gemini API access")

# Set Google Cloud credentials
credentials_path = os.path.join(os.path.dirname(__file__), "service-account-key.json", "gen-lang-client-0374473221-e19a8e500cef.json")
if os.path.exists(credentials_path):
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path
    print(f"Google Cloud credentials set: {credentials_path}")
else:
    print(f"Warning: Google Cloud credentials file not found: {credentials_path}")

# Initialize Vertex AI with explicit credentials
try:
    from google.oauth2 import service_account
    if os.path.exists(credentials_path):
        credentials = service_account.Credentials.from_service_account_file(credentials_path)
        vertexai.init(project=settings.GOOGLE_CLOUD_PROJECT_ID, location=settings.GOOGLE_CLOUD_LOCATION, credentials=credentials)
        print(f"Vertex AI initialized with explicit credentials for project: {settings.GOOGLE_CLOUD_PROJECT_ID}")
        
        # Initialize Google Gen AI SDK
        try:
            # Set environment variables for Vertex AI
            os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "true"
            os.environ["GOOGLE_CLOUD_PROJECT"] = settings.GOOGLE_CLOUD_PROJECT_ID
            os.environ["GOOGLE_CLOUD_LOCATION"] = settings.GOOGLE_CLOUD_LOCATION
            print("Google Gen AI SDK environment configured for Vertex AI")
        except Exception as genai_error:
            print(f"Google Gen AI SDK initialization failed: {genai_error}")
    else:
        vertexai.init(project=settings.GOOGLE_CLOUD_PROJECT_ID, location=settings.GOOGLE_CLOUD_LOCATION)
        print(f"Vertex AI initialized with default credentials for project: {settings.GOOGLE_CLOUD_PROJECT_ID}")
        
        # Initialize Google Gen AI SDK with default credentials
        try:
            # Set environment variables for Vertex AI
            os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "true"
            os.environ["GOOGLE_CLOUD_PROJECT"] = settings.GOOGLE_CLOUD_PROJECT_ID
            os.environ["GOOGLE_CLOUD_LOCATION"] = settings.GOOGLE_CLOUD_LOCATION
            print("Google Gen AI SDK environment configured for Vertex AI (default credentials)")
        except Exception as genai_error:
            print(f"Google Gen AI SDK initialization failed: {genai_error}")
except Exception as e:
    print(f"Warning: Vertex AI initialization failed: {e}")

SYSTEM_PROMPT_AIDS = """ä½ æ˜¯å°æä»è®°å¿†æ­å­ï¼Œè´Ÿè´£å¸®åŠ©ç”¨æˆ·è®°å¿†ã€‚ä½ ä¼šæ ¹æ®ç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼Œç”Ÿæˆæ€ç»´å¯¼å›¾ã€è®°å¿†å£è¯€å’Œæ„Ÿå®˜è”æƒ³ã€‚

è®°å¿†å£è¯€ç”Ÿæˆä¸‰ç§ç±»å‹ï¼šé¡ºå£æºœè®°å¿†æ³•ã€æ ¸å¿ƒå†…å®¹æ€»ç»“ã€è®°å¿†å®«æ®¿ç¼–ç ã€‚
æ„Ÿå®˜è”æƒ³ä¹Ÿåˆ†ä¸ºä¸‰ç±»ï¼šè§†è§‰è”æƒ³ã€å¬è§‰è”æƒ³å’Œè§¦è§‰è”æƒ³ã€‚

å¯¹äºæ ¸å¿ƒå†…å®¹æ€»ç»“ï¼Œè¯·æŒ‰ä»¥ä¸‹è¦æ±‚ï¼š
1. æç‚¼æ ¸å¿ƒè®ºç‚¹ï¼šç”¨ä¸€ä¸¤å¥è¯æ€»ç»“æ–‡æœ¬æœ€æ ¸å¿ƒã€æœ€æ€»ä½“çš„æ€æƒ³æˆ–è®ºç‚¹ï¼Œå¡«å…¥ corePoint å­—æ®µ
2. ç»“æ„åŒ–åˆ†è§£ï¼šå°†æ–‡æœ¬å†…å®¹åˆ†è§£ä¸ºå‡ ä¸ªå…³é”®çš„åŸåˆ™ã€è§‚ç‚¹æˆ–ä¸»è¦éƒ¨åˆ†ï¼Œå¡«å…¥ keyPrinciples æ•°ç»„
3. åŒºåˆ†è§‚ç‚¹ä¸ä¾‹å­ï¼šå¯¹äºæ¯ä¸€ç‚¹ï¼Œéƒ½å¿…é¡»æ¸…æ™°åœ°åˆ†ä¸ºè§‚ç‚¹/æ¦‚å¿µå’Œä¾‹å­/åšæ³•ä¸¤ä¸ªå±‚é¢
4. ç”Ÿæˆæ€»ç»“æè¿°ï¼šåŸºäºæ ¸å¿ƒè®ºç‚¹å’Œå…³é”®åŸåˆ™ï¼Œåœ¨ content å­—æ®µä¸­ç”Ÿæˆä¸€æ®µå®Œæ•´çš„ã€è¿è´¯çš„æ€»ç»“æ€§æè¿°ï¼Œå°†æ ¸å¿ƒè®ºç‚¹å’Œå„ä¸ªå…³é”®åŸåˆ™æœ‰æœºåœ°æ•´åˆæˆä¸€æ®µæ˜“äºç†è§£å’Œè®°å¿†çš„æ–‡å­—

å¯¹äºè®°å¿†å®«æ®¿ç¼–ç ï¼Œè¯·æŒ‰ä»¥ä¸‹è¦æ±‚ï¼š
1. è®¾å®šä¸»é¢˜ï¼šæ‰®æ¼”è®°å¿†å¤§å¸ˆçš„è§’è‰²ï¼Œä¸ºæ ¸å¿ƒå†…å®¹æ€»ç»“çš„æ‰€æœ‰è¦ç‚¹åˆ›å»ºä¸€ä¸ªå¯Œæœ‰æƒ³è±¡åŠ›çš„ã€ç»Ÿä¸€çš„"è®°å¿†å®«æ®¿"ä¸»é¢˜ï¼Œå¡«å…¥ theme å­—æ®µ
2. åˆ›å»ºåœºæ™¯ï¼šå°†æ€»ç»“ä¸­çš„æ¯ä¸€ä¸ªå…³é”®åŸåˆ™ï¼Œç²¾ç¡®åœ°æ˜ å°„åˆ°ä¸»é¢˜ä¸­çš„ä¸€ä¸ªå…·ä½“çš„"æˆ¿é—´"ã€"ç«™ç‚¹"ã€"åœºæ™¯"æˆ–"æ­¥éª¤"ï¼Œå¡«å…¥ scenes æ•°ç»„
3. æ³¨å…¥ç”ŸåŠ¨ç»†èŠ‚ï¼šä½¿ç”¨å¼ºçƒˆçš„è§†è§‰ã€åŠ¨ä½œå’Œæ„Ÿå®˜è¯­è¨€ï¼Œåˆ›é€ å…·ä½“ã€ç”ŸåŠ¨çš„ç”»é¢æ¥è±¡å¾æ€§åœ°ä»£è¡¨å¯¹åº”çš„åŸåˆ™å’Œä¾‹å­
4. æ˜ç¡®è¿æ¥ç‚¹ï¼šåœ¨æ¯ä¸ªåœºæ™¯æè¿°çš„ç»“å°¾ï¼Œç”¨æ˜ç¡®çš„"è®°å¿†é”šç‚¹"æ¥æ”¶å°¾ï¼Œå°†ç”ŸåŠ¨çš„ç”»é¢ä¸æŠ½è±¡æ¦‚å¿µç‰¢å›ºè”ç³»
5. ç”Ÿæˆå®«æ®¿æè¿°ï¼šåŸºäºè®°å¿†å®«æ®¿ä¸»é¢˜å’Œå„ä¸ªåœºæ™¯ï¼Œåœ¨ content å­—æ®µä¸­ç”Ÿæˆä¸€æ®µå®Œæ•´çš„ã€å¼•äººå…¥èƒœçš„è®°å¿†å®«æ®¿æ•´ä½“æè¿°ï¼Œå°†ä¸»é¢˜å’Œå„ä¸ªåœºæ™¯ä¸²è”æˆä¸€ä¸ªè¿è´¯çš„è®°å¿†æ•…äº‹

æ³¨æ„ä¸¥æ ¼æŒ‰ç…§å¦‚ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸éœ€è¦ä»»ä½•å¤šä½™çš„å†…å®¹ã€‚é‡è¦æé†’ï¼š
- å¿…é¡»å°†æ‰€æœ‰ [è¯·åœ¨æ­¤å¤„...] å ä½ç¬¦æ›¿æ¢ä¸ºå®é™…ç”Ÿæˆçš„å†…å®¹
- content å­—æ®µå¿…é¡»åŒ…å«å®Œæ•´çš„ã€æœ‰æ„ä¹‰çš„æè¿°æ–‡å­—ï¼Œä¸èƒ½ä¸ºç©º
- corePointã€theme ç­‰å­—æ®µä¹Ÿå¿…é¡»å¡«å…¥å…·ä½“å†…å®¹ï¼Œä¸èƒ½ä¿ç•™å ä½ç¬¦

JSONæ ¼å¼å¦‚ä¸‹ï¼š

{
  "mindMap": {
    "id": "root",
    "label": "æ ¹æ®ç”¨æˆ·è¾“å…¥å†…å®¹ç”Ÿæˆçš„ä¸»é¢˜æ ‡é¢˜",
    "children": [
      {
        "id": "part1",
        "label": "ç¬¬ä¸€ä¸ªä¸»è¦éƒ¨åˆ†çš„æ ‡é¢˜",
        "children": [
          { "id": "leaf1", "label": "ç¬¬ä¸€ä¸ªå­è¦ç‚¹" },
          { "id": "leaf2", "label": "ç¬¬äºŒä¸ªå­è¦ç‚¹" }
        ]
      },
      {
        "id": "part2",
        "label": "ç¬¬äºŒä¸ªä¸»è¦éƒ¨åˆ†çš„æ ‡é¢˜",
        "children": [
          { "id": "leaf3", "label": "ç¬¬ä¸‰ä¸ªå­è¦ç‚¹" },
          { "id": "leaf4", "label": "ç¬¬å››ä¸ªå­è¦ç‚¹" }
        ]
      }
    ]
  },
  "mnemonics": [
    {
      "id": "rhyme",
      "title": "é¡ºå£æºœè®°å¿†æ³•",
      "content": "æ ¹æ®ç”¨æˆ·å†…å®¹ç”Ÿæˆçš„é¡ºå£æºœæ–‡æœ¬",
      "type": "rhyme"
    },
    {
      "id": "summary",
      "title": "æ ¸å¿ƒå†…å®¹æ€»ç»“",
      "content": "åŸºäºæ ¸å¿ƒè®ºç‚¹å’Œå…³é”®åŸåˆ™çš„å®Œæ•´æ€»ç»“æè¿°",
      "type": "summary",
      "corePoint": "æ ¸å¿ƒè®ºç‚¹å†…å®¹",
      "keyPrinciples": [
        {
          "concept": "è§‚ç‚¹æˆ–æ¦‚å¿µ",
          "example": "å…·ä½“ä¾‹å­æˆ–åšæ³•"
        }
      ]
    },
    {
      "id": "palace",
      "title": "è®°å¿†å®«æ®¿ç¼–ç ",
      "content": "åŸºäºè®°å¿†å®«æ®¿ä¸»é¢˜å’Œåœºæ™¯çš„æ•´ä½“æè¿°",
      "type": "palace",
      "theme": "è®°å¿†å®«æ®¿ä¸»é¢˜",
      "scenes": [
        {
          "principle": "å¯¹åº”çš„åŸåˆ™",
          "scene": "ç”ŸåŠ¨çš„åœºæ™¯æè¿°",
          "anchor": "è®°å¿†é”šç‚¹"
        }
      ]
    }
  ],
  "sensoryAssociations": [
    {
      "id": "visual",
      "title": "è§†è§‰è”æƒ³",
      "type": "visual",
      "content": [
        {
          "dynasty": "ç¬¬ä¸€ä¸ªè§†è§‰è¦ç´ çš„åç§°",
          "image": "ğŸŒŸ",
          "color": "#fbbf24",
          "association": "å…·ä½“çš„è§†è§‰è”æƒ³æè¿°"
        },
        {
          "dynasty": "ç¬¬äºŒä¸ªè§†è§‰è¦ç´ çš„åç§°",
          "image": "ğŸ”µ",
          "color": "#06b6d4",
          "association": "å…·ä½“çš„è§†è§‰è”æƒ³æè¿°"
        }
      ]
    },
    {
      "id": "auditory",
      "title": "å¬è§‰è”æƒ³",
      "type": "auditory",
      "content": [
        { "dynasty": "ç¬¬ä¸€ä¸ªå¬è§‰è¦ç´ çš„åç§°", "sound": "å®å’šå£°", "rhythm": "èŠ‚å¥æ„Ÿ" },
        { "dynasty": "ç¬¬äºŒä¸ªå¬è§‰è¦ç´ çš„åç§°", "sound": "é£å£°", "rhythm": "è½»å¿«" }
      ]
    },
    {
      "id": "tactile",
      "title": "è§¦è§‰è”æƒ³",
      "type": "tactile",
      "content": [
        { "dynasty": "ç¬¬ä¸€ä¸ªè§¦è§‰è¦ç´ çš„åç§°", "texture": "æŸ”è½¯", "feeling": "æ¸©æš–" },
        { "dynasty": "ç¬¬äºŒä¸ªè§¦è§‰è¦ç´ çš„åç§°", "texture": "åšç¡¬", "feeling": "å†°å‡‰" }
      ]
    }
  ]
}

é‡è¦ï¼šä»¥ä¸ŠJSONä¸­çš„æ‰€æœ‰ç¤ºä¾‹æ–‡æœ¬ï¼ˆå¦‚"åŸºäºæ ¸å¿ƒè®ºç‚¹å’Œå…³é”®åŸåˆ™çš„å®Œæ•´æ€»ç»“æè¿°"ã€"æ ¸å¿ƒè®ºç‚¹å†…å®¹"ç­‰ï¼‰éƒ½å¿…é¡»æ›¿æ¢ä¸ºæ ¹æ®ç”¨æˆ·è¾“å…¥å†…å®¹å®é™…ç”Ÿæˆçš„å…·ä½“æ–‡å­—ï¼Œç»å¯¹ä¸èƒ½ä¿ç•™ç¤ºä¾‹æ–‡æœ¬æœ¬èº«ï¼
"""

# Although we ask Gemini for the schedule, it's more reliable to calculate it in code.
# The prompt serves as a logical guide, but the implementation is deterministic.
def generate_review_schedule_from_ebbinghaus():
    """
    Generates a review schedule based on the Ebbinghaus forgetting curve.
    """
    now = datetime.now()
    review_intervals = [
        timedelta(minutes=20),
        timedelta(hours=1),
        timedelta(hours=9),
        timedelta(days=1),
        timedelta(days=2),
        timedelta(days=4),
        timedelta(days=7),
        timedelta(days=15),
    ]
    review_dates = [(now + interval).isoformat() for interval in review_intervals]
    return {"review_dates": review_dates}

def parse_gemini_response(text: str):
    try:
        # Clean the text by removing ```json and ``` markers
        cleaned_text = re.sub(r'```json\n?|```', '', text)
        parsed_data = json.loads(cleaned_text)
        
        # Validate and fix mnemonics structure
        if 'mnemonics' in parsed_data and isinstance(parsed_data['mnemonics'], list):
            for i, mnemonic in enumerate(parsed_data['mnemonics']):
                if isinstance(mnemonic, dict):
                    # Check if type field is missing and add it based on id
                    if 'type' not in mnemonic:
                        if 'id' in mnemonic:
                            mnemonic['type'] = mnemonic['id']
                            logger.warning(f"[Parse Response] Added missing 'type' field to mnemonic {i}: {mnemonic['id']}")
                        else:
                            # Default type based on position
                            default_types = ['rhyme', 'summary', 'palace']
                            if i < len(default_types):
                                mnemonic['type'] = default_types[i]
                                logger.warning(f"[Parse Response] Added default 'type' field to mnemonic {i}: {default_types[i]}")
                            else:
                                mnemonic['type'] = 'unknown'
                                logger.warning(f"[Parse Response] Added fallback 'type' field to mnemonic {i}: unknown")
                    
                    # Check if content field is a list and convert to string
                    if 'content' in mnemonic and isinstance(mnemonic['content'], list):
                        # Convert list content to string representation
                        if mnemonic['content']:
                            # Try to extract meaningful text from the list
                            content_parts = []
                            for item in mnemonic['content']:
                                if isinstance(item, dict):
                                    # Extract text values from dict
                                    text_values = [str(v) for v in item.values() if isinstance(v, (str, int, float))]
                                    if text_values:
                                        content_parts.extend(text_values)
                                elif isinstance(item, str):
                                    content_parts.append(item)
                                else:
                                    content_parts.append(str(item))
                            mnemonic['content'] = ' '.join(content_parts) if content_parts else 'è®°å¿†å†…å®¹'
                        else:
                            mnemonic['content'] = 'è®°å¿†å†…å®¹'
                        logger.warning(f"[Parse Response] Converted list content to string for mnemonic {i}: {mnemonic.get('type', 'unknown')}")
        
        logger.info(f"[Parse Response] Successfully parsed and validated response")
        return parsed_data
    except Exception as e:
        logger.error(f"[Parse Response] Error parsing Gemini response: {e}")
        return None

async def call_gemini_via_proxy(prompt: str, model_name: str = "gemini-2.5-flash-002"):
    """é€šè¿‡ä»£ç†è°ƒç”¨Gemini API"""
    try:
        url = f"{settings.GEMINI_BASE_URL}/v1beta/models/{model_name}:generateContent"
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": settings.GEMINI_API_KEY
        }
        
        payload = {
            "contents": [{
                "parts": [{
                    "text": prompt
                }]
            }]
        }
        
        # è¯¦ç»†çš„è¯·æ±‚æ—¥å¿—
        logger.info(f"[Gemini Proxy] ===== REQUEST START =====")
        logger.info(f"[Gemini Proxy] URL: {url}")
        logger.info(f"[Gemini Proxy] Model: {model_name}")
        logger.info(f"[Gemini Proxy] Headers: {dict(headers)}")
        logger.info(f"[Gemini Proxy] Payload: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        logger.info(f"[Gemini Proxy] ===== REQUEST END =====")
        
        response = requests.post(url, headers=headers, json=payload, timeout=60)
        
        # è¯¦ç»†çš„å“åº”æ—¥å¿—
        logger.info(f"[Gemini Proxy] ===== RESPONSE START =====")
        logger.info(f"[Gemini Proxy] Status Code: {response.status_code}")
        logger.info(f"[Gemini Proxy] Response Headers: {dict(response.headers)}")
        logger.info(f"[Gemini Proxy] Raw Response Text: {response.text}")
        logger.info(f"[Gemini Proxy] ===== RESPONSE END =====")
        
        response.raise_for_status()
        
        result = response.json()
        
        if "candidates" in result and len(result["candidates"]) > 0:
            response_text = result["candidates"][0]["content"]["parts"][0]["text"]
            logger.info(f"[Gemini Proxy] Successfully extracted response text: {len(response_text)} characters")
            return response_text
        else:
            logger.error(f"[Gemini Proxy] Unexpected response format: {result}")
            return None
            
    except Exception as e:
        print(f"[Gemini Proxy Legacy] Error: {e}")
        return None

async def generate_memory_aids(content: str):
    """ç”Ÿæˆè®°å¿†è¾…åŠ©å†…å®¹ - ä½¿ç”¨æ–°çš„AIç®¡ç†å™¨"""
    try:
        # ä¼˜å…ˆä½¿ç”¨æ–°çš„AIç®¡ç†å™¨
        region = os.getenv("REGION", "global")
        logger.info(f"[Generate Memory Aids] ===== FUNCTION START =====")
        logger.info(f"[Generate Memory Aids] Region: {region}")
        logger.info(f"[Generate Memory Aids] Input content: {content}")
        
        if region in ["china", "global"]:
            logger.info(f"[Generate Memory Aids] Trying AI manager first...")
            result = ai_generate_memory_aids(content)
            if result:
                logger.info(f"[Generate Memory Aids] AI manager returned result: {json.dumps(result, ensure_ascii=False, indent=2)}")
                return result
            else:
                logger.info(f"[Generate Memory Aids] AI manager returned no result, falling back to Gemini")
        
        # å›é€€åˆ°åŸæœ‰çš„Geminiå®ç°ï¼ˆå‘åå…¼å®¹ï¼‰
        prompt = f"{SYSTEM_PROMPT_AIDS}\n\nç”¨æˆ·è¾“å…¥çš„å†…å®¹ï¼š{content}\n\nè¯·ä¸ºè¿™ä¸ªå†…å®¹ç”Ÿæˆè®°å¿†è¾…åŠ©å·¥å…·."
        
        logger.info(f"[Generate Memory Aids] Using fallback Gemini implementation")
        logger.info(f"[Generate Memory Aids] Full prompt: {prompt}")
        
        if settings.GEMINI_BASE_URL != "https://generativelanguage.googleapis.com":
            # ä½¿ç”¨ä»£ç†è°ƒç”¨
            logger.info(f"[Generate Memory Aids] Using Gemini proxy: {settings.GEMINI_BASE_URL}")
            response_text = await call_gemini_via_proxy(prompt)
        else:
            # ç›´æ¥ä½¿ç”¨SDKè°ƒç”¨
            logger.info(f"[Generate Memory Aids] Using direct Gemini SDK")
            logger.info(f"[Generate Memory Aids] Creating GenerativeModel with model: gemini-2.5-flash")
            model = genai.GenerativeModel('gemini-2.5-flash')
            logger.info(f"[Generate Memory Aids] Calling generate_content_async...")
            response = await model.generate_content_async(prompt)
            response_text = response.text
            logger.info(f"[Generate Memory Aids] SDK Response received: {response_text}")
        
        if response_text:
            logger.info(f"[Generate Memory Aids] Response text received, length: {len(response_text)} characters")
            logger.info(f"[Generate Memory Aids] Parsing JSON response...")
            parsed_response = parse_gemini_response(response_text)
            if parsed_response:
                logger.info(f"[Generate Memory Aids] Successfully parsed response: {json.dumps(parsed_response, ensure_ascii=False, indent=2)}")
            else:
                logger.error(f"[Generate Memory Aids] Failed to parse response. Raw text: {response_text}")
            logger.info(f"[Generate Memory Aids] ===== FUNCTION END =====")
            return parsed_response
        else:
            logger.error(f"[Generate Memory Aids] No response text received")
            logger.info(f"[Generate Memory Aids] ===== FUNCTION END =====")
            return None
    except Exception as e:
        logger.error(f"[Generate Memory Aids] Exception occurred: {str(e)}", exc_info=True)
        logger.info(f"[Generate Memory Aids] ===== FUNCTION END =====")
        return None

async def generate_image(content: str, context: str = ""):
    """
    Generate an actual image based on the visual association content using Google Imagen
    """
    # First, generate a detailed prompt using Gemini
    prompt_generation = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å›¾åƒç”Ÿæˆæç¤ºè¯ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹è§†è§‰è”æƒ³å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„ã€é€‚åˆAIå›¾åƒç”Ÿæˆçš„è‹±æ–‡æç¤ºè¯ã€‚

è§†è§‰è”æƒ³å†…å®¹ï¼š{content}
ä¸Šä¸‹æ–‡ï¼š{context}

è¦æ±‚ï¼š
1. æç¤ºè¯åº”è¯¥æ˜¯è‹±æ–‡
2. æè¿°è¦å…·ä½“ã€ç”ŸåŠ¨
3. é€‚åˆè®°å¿†è¾…åŠ©çš„è§†è§‰åŒ–è¡¨è¾¾
4. é£æ ¼æ¸…æ™°ã€è‰²å½©é²œæ˜
5. åªè¿”å›æç¤ºè¯ï¼Œä¸è¦å…¶ä»–å†…å®¹

ç¤ºä¾‹æ ¼å¼ï¼š"A vibrant illustration of..."
"""

    try:
        # Generate the prompt
        if settings.GEMINI_BASE_URL != "https://generativelanguage.googleapis.com":
            # ä½¿ç”¨ä»£ç†è°ƒç”¨
            image_prompt = await call_gemini_via_proxy(prompt_generation)
        else:
            # ç›´æ¥ä½¿ç”¨SDKè°ƒç”¨
            model = genai.GenerativeModel('gemini-2.5-flash-002')
            prompt_response = await model.generate_content_async(prompt_generation)
            image_prompt = prompt_response.text
        
        if image_prompt:
            image_prompt = image_prompt.strip()
        else:
            return None
        
        try:
            # Try to generate the actual image using Google Gen AI SDK
            try:
                # Use new Google Gen AI SDK
                client = google_genai.Client(vertexai=True)
                response = client.models.generate_images(
                    model="imagen-3.0-generate-002",
                    prompt=image_prompt,
                    config=types.GenerateImagesConfig(
                        number_of_images=1,
                        include_rai_reason=True,
                        output_mime_type='image/jpeg'
                    )
                )
                
                # Get the generated image
                generated_image = response.generated_images[0]
                
                # The generated_image.image is a google.genai.types.Image object with image_bytes attribute
                if hasattr(generated_image, 'image') and hasattr(generated_image.image, 'image_bytes'):
                    image_bytes = generated_image.image.image_bytes
                    image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                elif hasattr(generated_image, 'image_bytes'):
                    image_bytes = generated_image.image_bytes
                    image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                else:
                    raise Exception(f"Unknown image object structure: {type(generated_image)}, attributes: {dir(generated_image)}")
                
            except (NameError, AttributeError, ImportError) as fallback_error:
                print(f"Falling back to legacy Vertex AI API: {fallback_error}")
                # Fallback to old API
                generation_model = ImageGenerationModel.from_pretrained("imagen-3.0-generate-001")
                response = generation_model.generate_images(
                    prompt=image_prompt,
                    number_of_images=1,
                    aspect_ratio="1:1",
                    add_watermark=False,
                )
                
                # Get the generated image
                generated_image = response.images[0]
                image_bytes = generated_image._image_bytes
                image_base64 = base64.b64encode(image_bytes).decode('utf-8')
            
            return {
                "image_url": None,  # Imagen doesn't provide URLs, only image data
                "image_base64": f"data:image/png;base64,{image_base64}",
                "prompt": image_prompt
            }
        except Exception as imagen_error:
            print(f"Imagen generation failed: {imagen_error}")
            # Return error information when image generation fails
            error_message = str(imagen_error)
            if "429" in error_message or "out of capacity" in error_message:
                raise Exception("å›¾ç‰‡ç”ŸæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚Google ImagenæœåŠ¡å½“å‰å®¹é‡ä¸è¶³ã€‚")
            elif "Unable to authenticate" in error_message:
                raise Exception("å›¾ç‰‡ç”ŸæˆæœåŠ¡è®¤è¯å¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥é…ç½®ã€‚")
            else:
                raise Exception(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼š{error_message}")
            
            # This code won't be reached due to the raise above, but kept for reference
            return {
                "image_url": None,
                "image_base64": None,
                "prompt": image_prompt  # Still return the generated prompt
            }
            
    except Exception as e:
        print(f"Error generating image prompt: {e}")
        return {
            "image_url": None,
            "image_base64": None,
            "prompt": f"å›¾åƒç”Ÿæˆæç¤ºè¯ï¼š{content}çš„è§†è§‰åŒ–è¡¨è¾¾"  # Fallback prompt
        }

async def generate_audio(content: str, context: str = ""):
    """
    Generate actual audio based on the auditory association content.
    For environmental sounds (like truck engine), generate sound effects.
    For other content, use Text-to-Speech.
    """
    # Check if the content is requesting environmental sounds/effects
    environmental_sounds = [
        "å¼•æ“", "å‘åŠ¨æœº", "é©¬è¾¾", "æœºå™¨", "é£å£°", "é›¨å£°", "é›¨æ»´", "æµ·æµª", "é¸Ÿå«", "è™«é¸£", 
        "é›·å£°", "é’Ÿå£°", "è­¦æŠ¥", "æ±½ç¬›", "å–‡å­", "æ•²å‡»", "æ‘©æ“¦", "æ»´æ°´", "æµæ°´",
        "è„šæ­¥", "å¿ƒè·³", "å‘¼å¸", "å’€åš¼", "æ’•çº¸", "å¼€é—¨", "å…³é—¨", "é”®ç›˜", "é¼ æ ‡",
        "è½°é¸£", "å—¡å—¡", "å’”åš“", "æ»´ç­”", "å‘¼å‘¼", "å“—å“—", "å®å’š", "å˜€å—’"
    ]
    
    is_environmental_sound = any(sound in content for sound in environmental_sounds)
    
    if is_environmental_sound:
        # For environmental sounds, generate a synthetic sound effect description
        # and return a placeholder for actual sound generation
        model = genai.GenerativeModel('gemini-2.5-flash-002')
        sound_description = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å£°éŸ³æ•ˆæœæè¿°ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹å£°éŸ³å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„å£°éŸ³ç‰¹å¾æè¿°ã€‚

å£°éŸ³å†…å®¹ï¼š{content}
ä¸Šä¸‹æ–‡ï¼š{context}

è¦æ±‚ï¼š
1. æè¿°å£°éŸ³çš„é¢‘ç‡ç‰¹å¾ï¼ˆä½é¢‘ã€ä¸­é¢‘ã€é«˜é¢‘ï¼‰
2. æè¿°å£°éŸ³çš„èŠ‚å¥å’ŒæŒç»­æ€§
3. æè¿°å£°éŸ³çš„å¼ºåº¦å˜åŒ–
4. ç”¨ä¸“ä¸šæœ¯è¯­æè¿°å£°éŸ³ç‰¹å¾
5. é•¿åº¦æ§åˆ¶åœ¨100å­—ä»¥å†…

ç¤ºä¾‹æ ¼å¼ï¼š"ä½é¢‘æŒç»­è½°é¸£ï¼Œé¢‘ç‡çº¦50-200Hzï¼ŒèŠ‚å¥ç¨³å®šï¼Œå¼ºåº¦ä¸­ç­‰ï¼Œå¸¦æœ‰è½»å¾®çš„æœºæ¢°æŒ¯åŠ¨æ„Ÿ..."
"""
        
        try:
            response = await model.generate_content_async(sound_description)
            sound_spec = response.text.strip()
            
            # Return a structured response for environmental sounds
            return {
                "audio_base64": None,  # No actual audio generated yet
                "script": f"ç¯å¢ƒéŸ³æ•ˆï¼š{content}",
                "sound_description": sound_spec,
                "sound_type": "environmental",
                "duration": 5.0,  # Default 5 seconds for environmental sounds
                "message": "å·²ç”Ÿæˆå£°éŸ³ç‰¹å¾æè¿°ï¼Œå®é™…éŸ³æ•ˆç”ŸæˆåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
            }
        except Exception as e:
            print(f"Error generating sound description: {e}")
            return {
                "audio_base64": None,
                "script": f"ç¯å¢ƒéŸ³æ•ˆï¼š{content}",
                "sound_description": f"è¯·æ±‚çš„å£°éŸ³ï¼š{content}ï¼Œç‰¹å¾ï¼šæŒç»­æ€§ç¯å¢ƒéŸ³æ•ˆ",
                "sound_type": "environmental",
                "duration": 5.0,
                "message": "å£°éŸ³ç‰¹å¾æè¿°ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æè¿°"
            }
    
    # For non-environmental sounds, return development message instead of calling TTS API
    try:
        # Generate a simple script description without calling the model
        audio_script = f"å¬è§‰è”æƒ³ï¼š{content}"
        
        return {
            "audio_base64": None,
            "script": audio_script,
            "duration": 3.0,  # Default duration
            "message": "è¯­éŸ³åˆæˆåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
        }
        
    except Exception as e:
        print(f"Error generating audio script: {e}")
        return {
            "audio_base64": None,
            "script": f"å¬è§‰è”æƒ³ï¼š{content}",
            "duration": 3.0,
            "message": "è¯­éŸ³åˆæˆåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­"
        }

